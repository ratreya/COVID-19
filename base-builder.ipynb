{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import kaggle as kg\n",
    "from datetime import date, timedelta, datetime\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "def cleanup(merged):\n",
    "    # Standerdize Country Names\n",
    "    merged['Country'].replace('United Kingdom', 'UK', inplace=True)\n",
    "    merged['Country'].replace('Mainland China', 'China', inplace=True)\n",
    "    merged['Country'].replace(['Korea, South', 'Republic of Korea'], 'South Korea', inplace=True)\n",
    "    merged['Country'].replace('Iran (Islamic Republic of)', 'Iran',inplace=True)\n",
    "\n",
    "    # Standerdize US State Names\n",
    "    merged['State'] = merged['State'].str.strip()\n",
    "    merged['State'].replace(regex={'^.*Virgin Islands.*$': 'Virgin Islands'}, inplace=True)\n",
    "    merged['State'].replace(regex={'^(.+) \\(From Diamond Princess\\)$': r'\\1'}, inplace=True)\n",
    "    merged['State'].replace(regex={'^.*Princess.*$': 'Cruise Ship'}, inplace=True)\n",
    "    merged['State'].replace(regex={'^.+, (.+)$': r'\\1'}, inplace=True)\n",
    "    merged['State'].replace(['District of Columbia', 'D.C.'], 'DC', inplace=True)\n",
    "    merged['State'].replace('Chicago', 'IL', inplace=True)\n",
    "    us_state_abbrev = {\n",
    "        'Alabama': 'AL',\n",
    "        'Alaska': 'AK',\n",
    "        'American Samoa': 'AS',\n",
    "        'Arizona': 'AZ',\n",
    "        'Arkansas': 'AR',\n",
    "        'California': 'CA',\n",
    "        'Colorado': 'CO',\n",
    "        'Connecticut': 'CT',\n",
    "        'Delaware': 'DE',\n",
    "        'District of Columbia': 'DC',\n",
    "        'Florida': 'FL',\n",
    "        'Georgia': 'GA',\n",
    "        'Guam': 'GU',\n",
    "        'Hawaii': 'HI',\n",
    "        'Idaho': 'ID',\n",
    "        'Illinois': 'IL',\n",
    "        'Indiana': 'IN',\n",
    "        'Iowa': 'IA',\n",
    "        'Kansas': 'KS',\n",
    "        'Kentucky': 'KY',\n",
    "        'Louisiana': 'LA',\n",
    "        'Maine': 'ME',\n",
    "        'Maryland': 'MD',\n",
    "        'Massachusetts': 'MA',\n",
    "        'Michigan': 'MI',\n",
    "        'Minnesota': 'MN',\n",
    "        'Mississippi': 'MS',\n",
    "        'Missouri': 'MO',\n",
    "        'Montana': 'MT',\n",
    "        'Nebraska': 'NE',\n",
    "        'Nevada': 'NV',\n",
    "        'New Hampshire': 'NH',\n",
    "        'New Jersey': 'NJ',\n",
    "        'New Mexico': 'NM',\n",
    "        'New York': 'NY',\n",
    "        'North Carolina': 'NC',\n",
    "        'North Dakota': 'ND',\n",
    "        'Northern Mariana Islands':'MP',\n",
    "        'Ohio': 'OH',\n",
    "        'Oklahoma': 'OK',\n",
    "        'Oregon': 'OR',\n",
    "        'Pennsylvania': 'PA',\n",
    "        'Puerto Rico': 'PR',\n",
    "        'Rhode Island': 'RI',\n",
    "        'South Carolina': 'SC',\n",
    "        'South Dakota': 'SD',\n",
    "        'Tennessee': 'TN',\n",
    "        'Texas': 'TX',\n",
    "        'Utah': 'UT',\n",
    "        'Vermont': 'VT',\n",
    "        'Virgin Islands': 'VI',\n",
    "        'Virginia': 'VA',\n",
    "        'Washington': 'WA',\n",
    "        'West Virginia': 'WV',\n",
    "        'Wisconsin': 'WI',\n",
    "        'Wyoming': 'WY'\n",
    "    }\n",
    "    merged['State'].replace(us_state_abbrev, inplace=True)\n",
    "    \n",
    "def fillin(merged):\n",
    "    # Fill NaNs otherwise some operations such as gorupby will not work\n",
    "    merged['Confirmed'].fillna(0, inplace=True)\n",
    "    merged['Deaths'].fillna(0, inplace=True)\n",
    "    merged['Recovered'].fillna(0, inplace=True)\n",
    "    merged['State'].fillna('n/a', inplace=True)\n",
    "    merged['County'].fillna('n/a', inplace=True)\n",
    "    return merged\n",
    "\n",
    "def verify(merged):\n",
    "    # Run verifications - ignore small deviations\n",
    "    df_neg = merged[(merged['County'] != 'Unassigned') & (merged['Confirmed_New'] < -100) | (merged['Deaths_New'] < -50) | (merged['Recovered_New'] < -50)]\n",
    "    if df_neg.shape[0] > 0:\n",
    "        print('Some deltas are hugely negative!')\n",
    "        print(df_neg.sort_values('Confirmed_New'))\n",
    "\n",
    "    mismatch = merged[(merged['State'] != 'US') & (merged['State'] != 'Recovered') & (merged['County'] != 'Unassigned') & (merged['Confirmed'] - (merged['Deaths'] + merged['Recovered']) < -10)]\n",
    "    if mismatch.shape[0] > 0:\n",
    "        print('Confirmed is much smaller than Deaths + Recovered!')\n",
    "        print(mismatch)\n",
    "\n",
    "def jhu():\n",
    "    # Get list of days in expected format\n",
    "    sdate = date(2020, 1, 22)\n",
    "    today = date.today()\n",
    "    edate = date(today.year, today.month, today.day)\n",
    "    days = [(sdate + timedelta(days=i)).strftime('%m-%d-%Y') for i in range((edate - sdate).days + 1)]\n",
    "\n",
    "    # Merge all daily reports\n",
    "    url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/%s.csv'\n",
    "    with ThreadPoolExecutor(max_workers=100) as executor:\n",
    "        futures = [executor.submit(lambda day: (day, pd.read_csv(url % day)), day) for day in days]\n",
    "\n",
    "    merged = pd.DataFrame(columns = ['Country', 'State', 'County', 'Date', 'Confirmed', 'Deaths', 'Recovered', 'Confirmed_New', 'Deaths_New', 'Recovered_New', 'Confirmed_Doubling'])\n",
    "    for future in as_completed(futures):\n",
    "        try:\n",
    "            day, df = future.result()\n",
    "            # Fix changes in column names if they exits\n",
    "            df = df.rename({'Admin2': 'County', 'Province/State':'State', 'Country/Region':'Country', 'Province_State':'State', 'Country_Region':'Country'}, axis=1)\n",
    "            df.drop([x for x in df.columns.values if x not in merged.columns.values], axis=1, inplace=True)\n",
    "            df['Date'] = day\n",
    "            merged = pd.concat([merged, df])\n",
    "        except IOError as e:\n",
    "            print(str(e))\n",
    "\n",
    "    # Clean up the data\n",
    "    cleanup(merged)\n",
    "    fillin(merged)\n",
    "\n",
    "    # Fix bad data\n",
    "    merged.loc[(merged['State'] == 'French Polynesia') & (merged['Date'] == '03-23-2020'), 'State'] = 'n/a'\n",
    "    merged.loc[(merged['Country'] == 'France') & (merged['State'] == 'France'), 'State'] = 'n/a'\n",
    "\n",
    "    # Do this because there are duplicate rows in some datasets\n",
    "    return merged.groupby(['Country', 'State', 'County', 'Date'], as_index=False).sum()\n",
    "\n",
    "def india(merged):\n",
    "    kg.api.authenticate()\n",
    "    kg.api.dataset_download_file('sudalairajkumar/covid19-in-india', 'covid_19_india.csv')\n",
    "    df = pd.read_csv('covid_19_india.csv')\n",
    "    df.Date = [datetime.strptime(x, '%d/%m/%y').strftime('%m-%d-%Y') for x in df.Date]\n",
    "    df = df.rename({'State/UnionTerritory': 'State', 'Cured': 'Recovered'}, axis=1)\n",
    "    df.drop([x for x in df.columns.values if x not in merged.columns.values], axis=1, inplace=True)\n",
    "    df['Country'] = 'India'\n",
    "    df['County'] = 'n/a'\n",
    "    return fillin(pd.concat([merged, df]))\n",
    "\n",
    "def deltas(merged):\n",
    "    def deltas(df):\n",
    "        for state in df['State'].unique():\n",
    "            for county in df[df['State'] == state]['County'].unique():\n",
    "                confirmed = df[(df['State'] == state) & (df['County'] == county)]['Confirmed'].values.tolist()\n",
    "                confirmed_deltas = [np.nan] + [confirmed[i] - confirmed[i-1] for i in range(1, len(confirmed))]\n",
    "                df.loc[(df['State'] == state) & (df['County'] == county), 'Confirmed_New'] = confirmed_deltas\n",
    "                deaths = df[(df['State'] == state) & (df['County'] == county)]['Deaths'].values.tolist()\n",
    "                deaths_deltas = [np.nan] + [deaths[i] - deaths[i-1] for i in range(1, len(deaths))]\n",
    "                df.loc[(df['State'] == state) & (df['County'] == county), 'Deaths_New'] = deaths_deltas\n",
    "                recovered = df[(df['State'] == state) & (df['County'] == county)]['Recovered'].values.tolist()\n",
    "                recovered_deltas = [np.nan] + [recovered[i] - recovered[i-1] for i in range(1, len(recovered))]\n",
    "                df.loc[(df['State'] == state) & (df['County'] == county), 'Recovered_New'] = recovered_deltas\n",
    "        return df\n",
    "\n",
    "    # Calculate deltas for each date\n",
    "    with ThreadPoolExecutor(max_workers=100) as executor:\n",
    "        futures = [executor.submit(deltas, merged[(merged['Country'] == 'US') & (merged['State'] == state)].copy()) for state in merged[merged['Country'] == 'US'].State.unique()]\n",
    "        futures += [executor.submit(deltas, merged[merged['Country'] == country].copy()) for country in merged.Country.unique() if country != 'US']\n",
    "\n",
    "    final = pd.DataFrame(columns=merged.columns)\n",
    "    for future in as_completed(futures):\n",
    "        df = future.result()\n",
    "        final = pd.concat([final, df])\n",
    "\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some deltas are hugely negative!\n",
      "                   Country      State         County        Date  Confirmed  \\\n",
      "19664                Spain        n/a            n/a  04-30-2020   213435.0   \n",
      "10291               France        n/a            n/a  04-14-2020   130253.0   \n",
      "10306               France        n/a            n/a  04-29-2020   165093.0   \n",
      "10299               France        n/a            n/a  04-22-2020   155860.0   \n",
      "117727                  US         NJ     Unassigned  04-22-2020     1045.0   \n",
      "8959               Ecuador        n/a            n/a  05-07-2020    30298.0   \n",
      "8960               Ecuador        n/a            n/a  05-08-2020    28818.0   \n",
      "121939                  US         NY  New York City  04-23-2020   145855.0   \n",
      "14266                Japan        n/a            n/a  04-28-2020    13736.0   \n",
      "122214                  US         NY         Orange  04-23-2020     6816.0   \n",
      "117143                  US         NJ         Hudson  05-13-2020    17451.0   \n",
      "10320               France        n/a            n/a  05-13-2020   175981.0   \n",
      "122434                  US         NY         Putnam  04-23-2020      615.0   \n",
      "144463                  US         TN       Davidson  04-17-2020     1307.0   \n",
      "158384                  US         TX         Taylor  05-07-2020      206.0   \n",
      "17991             Portugal        n/a            n/a  05-02-2020    25190.0   \n",
      "179533  West Bank and Gaza        n/a            n/a  04-25-2020      342.0   \n",
      "144459                  US         TN       Davidson  04-13-2020     1207.0   \n",
      "137795                  US         PR            n/a  04-24-2020     1276.0   \n",
      "117142                  US         NJ         Hudson  05-12-2020    17677.0   \n",
      "30522                   US         AZ         Navajo  04-09-2020      286.0   \n",
      "116329                  US         NH   Hillsborough  04-14-2020      271.0   \n",
      "107311                  US         NC      Granville  04-28-2020      133.0   \n",
      "15156            Lithuania        n/a            n/a  04-28-2020     1344.0   \n",
      "82302                   US         MA     Unassigned  04-25-2020      753.0   \n",
      "82304                   US         MA     Unassigned  04-27-2020      795.0   \n",
      "123272                  US         NY     Unassigned  04-19-2020        0.0   \n",
      "123263                  US         NY     Unassigned  04-10-2020        0.0   \n",
      "123262                  US         NY     Unassigned  04-09-2020        0.0   \n",
      "123260                  US         NY     Unassigned  04-07-2020        0.0   \n",
      "123259                  US         NY     Unassigned  04-06-2020        0.0   \n",
      "138217                  US  Recovered            n/a  05-12-2020        0.0   \n",
      "123273                  US         NY     Unassigned  04-20-2020        0.0   \n",
      "83601                   US         MD     Unassigned  04-27-2020        0.0   \n",
      "167674                  US         VA     Unassigned  04-22-2020        0.0   \n",
      "67239                   US         IN     Unassigned  05-02-2020        0.0   \n",
      "3740                Canada  Recovered            n/a  04-01-2020        0.0   \n",
      "10576              Germany    Unknown            n/a  05-15-2020     1450.0   \n",
      "1240             Australia   Victoria            n/a  04-25-2020     1346.0   \n",
      "82292                   US         MA     Unassigned  04-15-2020      572.0   \n",
      "82288                   US         MA     Unassigned  04-11-2020      225.0   \n",
      "5629                 China      Hubei            n/a  04-17-2020    68128.0   \n",
      "16828          Netherlands        n/a            n/a  04-21-2020    34134.0   \n",
      "117706                  US         NJ     Unassigned  04-01-2020     4512.0   \n",
      "10309               France        n/a            n/a  05-02-2020   166976.0   \n",
      "121954                  US         NY  New York City  05-08-2020   181783.0   \n",
      "21433                   UK        n/a            n/a  04-13-2020    88621.0   \n",
      "\n",
      "         Deaths  Recovered  Confirmed_New  Deaths_New  Recovered_New  \n",
      "19664   24543.0   112050.0       -23464.0       268.0       -20879.0  \n",
      "10291   15729.0    28805.0        -6526.0       762.0         1087.0  \n",
      "10306   24087.0    48228.0        -2512.0       427.0         1342.0  \n",
      "10299   21340.0    40657.0        -2190.0       544.0         1476.0  \n",
      "117727      0.0        0.0        -2028.0      -233.0            0.0  \n",
      "8959     1654.0     3433.0        -1583.0        36.0            0.0  \n",
      "8960     1704.0     3433.0        -1480.0        50.0            0.0  \n",
      "121939  16388.0        0.0        -1442.0      1314.0            0.0  \n",
      "14266     394.0     1899.0         -417.0         9.0            0.0  \n",
      "122214    268.0        0.0         -336.0        24.0            0.0  \n",
      "117143   1007.0        0.0         -226.0         7.0            0.0  \n",
      "10320   27032.0    57368.0         -217.0        81.0          753.0  \n",
      "122434      7.0        0.0         -216.0         0.0            0.0  \n",
      "144463     19.0        0.0         -185.0         0.0            0.0  \n",
      "158384      6.0        0.0         -172.0         0.0            0.0  \n",
      "17991    1023.0     1671.0         -161.0        16.0           24.0  \n",
      "179533      2.0       92.0         -142.0        -2.0            0.0  \n",
      "144459     16.0        0.0         -142.0         3.0            0.0  \n",
      "137795     77.0        0.0         -140.0         8.0            0.0  \n",
      "117142   1000.0        0.0         -124.0         4.0            0.0  \n",
      "30522       1.0        0.0         -118.0         0.0            0.0  \n",
      "116329      0.0        0.0         -114.0        -2.0            0.0  \n",
      "107311      5.0        0.0         -107.0         0.0            0.0  \n",
      "15156      44.0      536.0         -105.0         3.0           62.0  \n",
      "82302      13.0        0.0          -38.0      -590.0            0.0  \n",
      "82304       8.0        0.0          -12.0      -133.0            0.0  \n",
      "123272    401.0        0.0            0.0      -658.0            0.0  \n",
      "123263      0.0        0.0            0.0       -73.0            0.0  \n",
      "123262     73.0        0.0            0.0       -79.0            0.0  \n",
      "123260    116.0        0.0            0.0      -193.0            0.0  \n",
      "123259    309.0        0.0            0.0      -951.0            0.0  \n",
      "138217      0.0   230287.0            0.0         0.0        -2446.0  \n",
      "123273     48.0        0.0            0.0      -353.0            0.0  \n",
      "83601      87.0        0.0            0.0       -58.0            0.0  \n",
      "167674      0.0        0.0            0.0      -140.0            0.0  \n",
      "67239       0.0        0.0            0.0      -113.0            0.0  \n",
      "3740        0.0     1324.0            0.0         0.0         -268.0  \n",
      "10576       0.0        0.0            3.0       -72.0         -123.0  \n",
      "1240       16.0      133.0            3.0         0.0        -1039.0  \n",
      "82292      14.0        0.0           66.0       -86.0            0.0  \n",
      "82288      13.0        0.0           96.0      -166.0            0.0  \n",
      "5629     4512.0    63487.0          325.0      1290.0         -948.0  \n",
      "16828    3916.0        0.0          729.0       165.0         -250.0  \n",
      "117706      0.0        0.0          826.0      -247.0            0.0  \n",
      "10309   24729.0    49751.0         1212.0       135.0         -461.0  \n",
      "121954  19561.0        0.0         1567.0       -65.0            0.0  \n",
      "21433   11329.0        0.0         4342.0       717.0         -344.0  \n",
      "Confirmed is much smaller than Deaths + Recovered!\n",
      "      Country          State County        Date  Confirmed  Deaths  Recovered  \\\n",
      "19545   Spain  C. Valenciana    n/a  05-14-2020    10784.0  1349.0     9490.0   \n",
      "19546   Spain  C. Valenciana    n/a  05-15-2020    10813.0  1358.0     9708.0   \n",
      "19549   Spain      Cantabria    n/a  05-14-2020     2256.0   205.0     2110.0   \n",
      "19550   Spain      Cantabria    n/a  05-15-2020     2263.0   206.0     2152.0   \n",
      "19557   Spain          Ceuta    n/a  05-14-2020      116.0     4.0      159.0   \n",
      "19558   Spain          Ceuta    n/a  05-15-2020      116.0     4.0      160.0   \n",
      "19559   Spain    Extremadura    n/a  05-14-2020     2923.0   492.0     2482.0   \n",
      "19560   Spain    Extremadura    n/a  05-15-2020     2933.0   494.0     2587.0   \n",
      "19569   Spain         Murcia    n/a  05-14-2020     1532.0   142.0     1998.0   \n",
      "19570   Spain         Murcia    n/a  05-15-2020     1534.0   143.0     2034.0   \n",
      "19573   Spain     Pais Vasco    n/a  05-14-2020    13219.0  1454.0    15256.0   \n",
      "19574   Spain     Pais Vasco    n/a  05-15-2020    13257.0  1454.0    15256.0   \n",
      "\n",
      "       Confirmed_New  Deaths_New  Recovered_New  \n",
      "19545            0.0         0.0            0.0  \n",
      "19546           29.0         9.0          218.0  \n",
      "19549            0.0         0.0            0.0  \n",
      "19550            7.0         1.0           42.0  \n",
      "19557            0.0         0.0            0.0  \n",
      "19558            0.0         0.0            1.0  \n",
      "19559            0.0         0.0            0.0  \n",
      "19560           10.0         2.0          105.0  \n",
      "19569            0.0         0.0            0.0  \n",
      "19570            2.0         1.0           36.0  \n",
      "19573            0.0         0.0            0.0  \n",
      "19574           38.0         0.0            0.0  \n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "merged = jhu()\n",
    "merged = india(merged[merged['Country'] != 'India'])\n",
    "merged = deltas(merged)\n",
    "merged = merged.groupby(['Country', 'State', 'County', 'Date'], as_index=False).sum()\n",
    "\n",
    "# Write merged to CSV and verify\n",
    "merged.to_csv('jhu-daily-reports.csv', index=False)\n",
    "verify(merged)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
