{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error 404: Not Found for: 03-29-2020\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date, timedelta\n",
    "\n",
    "# Get list of days in expected format\n",
    "sdate = date(2020, 1, 22)\n",
    "today = date.today()\n",
    "edate = date(today.year, today.month, today.day)\n",
    "days = [(sdate + timedelta(days=i)).strftime('%m-%d-%Y') for i in range((edate - sdate).days + 1)]\n",
    "\n",
    "# Merge all daily reports\n",
    "merged = pd.DataFrame(columns = ['Country', 'State', 'County', 'Date', 'Confirmed', 'Deaths', 'Recovered', 'Confirmed_New', 'Deaths_New', 'Recovered_New'])\n",
    "error_days = set()\n",
    "for day in days:\n",
    "    url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/' + day + '.csv'\n",
    "    try:\n",
    "        df = pd.read_csv(url)\n",
    "        # Fix changes in column names if they exits\n",
    "        df = df.rename({'Admin2': 'County', 'Province/State':'State', 'Country/Region':'Country', 'Province_State':'State', 'Country_Region':'Country'}, axis=1)\n",
    "        df.drop([x for x in df.columns.values if x not in merged.columns.values], axis=1, inplace=True)\n",
    "        df.insert(2, 'Date', [day for i in range(df.shape[0])])\n",
    "        merged = pd.concat([merged, df])\n",
    "    except IOError as e:\n",
    "        print(str(e) + ' for: ' + day)\n",
    "        error_days.add(day)\n",
    "\n",
    "# Remove any days that errored out\n",
    "days = [x for x in days if x not in error_days]\n",
    "\n",
    "# Standerdize Country Names\n",
    "pd.options.mode.chained_assignment = None\n",
    "merged['Country'].replace('United Kingdom', 'UK', inplace=True)\n",
    "merged['Country'].replace('Mainland China', 'China', inplace=True)\n",
    "merged['Country'].replace(['Korea, South', 'Republic of Korea'], 'South Korea', inplace=True)\n",
    "merged['Country'].replace('Iran (Islamic Republic of)', 'Iran',inplace=True)\n",
    "\n",
    "# Standerdize US State Names\n",
    "merged['State'] = merged['State'].str.strip()\n",
    "merged['State'].replace(regex={'^.*Virgin Islands.*$': 'Virgin Islands'}, inplace=True)\n",
    "merged['State'].replace(regex={'^(.+) \\(From Diamond Princess\\)$': r'\\1'}, inplace=True)\n",
    "merged['State'].replace(regex={'^.*Princess.*$': 'Cruise Ship'}, inplace=True)\n",
    "merged['State'].replace(regex={'^.+, (.+)$': r'\\1'}, inplace=True)\n",
    "merged['State'].replace(['District of Columbia', 'D.C.'], 'DC', inplace=True)\n",
    "merged['State'].replace('Chicago', 'IL', inplace=True)\n",
    "us_state_abbrev = {\n",
    "    'Alabama': 'AL',\n",
    "    'Alaska': 'AK',\n",
    "    'American Samoa': 'AS',\n",
    "    'Arizona': 'AZ',\n",
    "    'Arkansas': 'AR',\n",
    "    'California': 'CA',\n",
    "    'Colorado': 'CO',\n",
    "    'Connecticut': 'CT',\n",
    "    'Delaware': 'DE',\n",
    "    'District of Columbia': 'DC',\n",
    "    'Florida': 'FL',\n",
    "    'Georgia': 'GA',\n",
    "    'Guam': 'GU',\n",
    "    'Hawaii': 'HI',\n",
    "    'Idaho': 'ID',\n",
    "    'Illinois': 'IL',\n",
    "    'Indiana': 'IN',\n",
    "    'Iowa': 'IA',\n",
    "    'Kansas': 'KS',\n",
    "    'Kentucky': 'KY',\n",
    "    'Louisiana': 'LA',\n",
    "    'Maine': 'ME',\n",
    "    'Maryland': 'MD',\n",
    "    'Massachusetts': 'MA',\n",
    "    'Michigan': 'MI',\n",
    "    'Minnesota': 'MN',\n",
    "    'Mississippi': 'MS',\n",
    "    'Missouri': 'MO',\n",
    "    'Montana': 'MT',\n",
    "    'Nebraska': 'NE',\n",
    "    'Nevada': 'NV',\n",
    "    'New Hampshire': 'NH',\n",
    "    'New Jersey': 'NJ',\n",
    "    'New Mexico': 'NM',\n",
    "    'New York': 'NY',\n",
    "    'North Carolina': 'NC',\n",
    "    'North Dakota': 'ND',\n",
    "    'Northern Mariana Islands':'MP',\n",
    "    'Ohio': 'OH',\n",
    "    'Oklahoma': 'OK',\n",
    "    'Oregon': 'OR',\n",
    "    'Pennsylvania': 'PA',\n",
    "    'Puerto Rico': 'PR',\n",
    "    'Rhode Island': 'RI',\n",
    "    'South Carolina': 'SC',\n",
    "    'South Dakota': 'SD',\n",
    "    'Tennessee': 'TN',\n",
    "    'Texas': 'TX',\n",
    "    'Utah': 'UT',\n",
    "    'Vermont': 'VT',\n",
    "    'Virgin Islands': 'VI',\n",
    "    'Virginia': 'VA',\n",
    "    'Washington': 'WA',\n",
    "    'West Virginia': 'WV',\n",
    "    'Wisconsin': 'WI',\n",
    "    'Wyoming': 'WY'\n",
    "}\n",
    "merged['State'].replace(us_state_abbrev, inplace=True)\n",
    "\n",
    "merged['Confirmed'].fillna(0, inplace=True)\n",
    "merged['Deaths'].fillna(0, inplace=True)\n",
    "merged['Recovered'].fillna(0, inplace=True)\n",
    "merged['State'].fillna('n/a', inplace=True)\n",
    "merged['County'].fillna('n/a', inplace=True)\n",
    "\n",
    "# Fix bad data\n",
    "merged.loc[(merged['State'] == 'French Polynesia') & (merged['Date'] == '03-23-2020'), 'State'] = 'n/a'\n",
    "\n",
    "# Do this because there are duplicate rows in some datasets\n",
    "merged = merged.groupby(['Country', 'State', 'County', 'Date'], as_index=False).sum()\n",
    "\n",
    "# Calculate deltas for each date\n",
    "for country in merged['Country'].unique():\n",
    "    for state in merged[merged['Country'] == country]['State'].unique():\n",
    "        for county in merged[(merged['Country'] == country) & (merged['State'] == state)]['County'].unique():\n",
    "            confirmed = merged[(merged['Country'] == country) & (merged['State'] == state) & (merged['County'] == county)]['Confirmed'].values.tolist()\n",
    "            confirmed_deltas = [np.nan] + [confirmed[i] - confirmed[i-1] for i in range(1, len(confirmed))]\n",
    "            merged.loc[(merged['Country'] == country) & (merged['State'] == state) & (merged['County'] == county), 'Confirmed_New'] = confirmed_deltas\n",
    "            deaths = merged[(merged['Country'] == country) & (merged['State'] == state) & (merged['County'] == county)]['Deaths'].values.tolist()\n",
    "            deaths_deltas = [np.nan] + [deaths[i] - deaths[i-1] for i in range(1, len(deaths))]\n",
    "            merged.loc[(merged['Country'] == country) & (merged['State'] == state) & (merged['County'] == county), 'Deaths_New'] = deaths_deltas\n",
    "            recovered = merged[(merged['Country'] == country) & (merged['State'] == state) & (merged['County'] == county)]['Recovered'].values.tolist()\n",
    "            recovered_deltas = [np.nan] + [recovered[i] - recovered[i-1] for i in range(1, len(recovered))]\n",
    "            merged.loc[(merged['Country'] == country) & (merged['State'] == state) & (merged['County'] == county), 'Recovered_New'] = recovered_deltas\n",
    "\n",
    "merged.to_csv('covid-merged-daily-reports.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Country State County        Date  Confirmed  Deaths  Recovered  \\\n",
      "4221  France   n/a    n/a  01-24-2020        2.0     0.0        0.0   \n",
      "4222  France   n/a    n/a  01-25-2020        3.0     0.0        0.0   \n",
      "4223  France   n/a    n/a  01-26-2020        3.0     0.0        0.0   \n",
      "4224  France   n/a    n/a  01-27-2020        3.0     0.0        0.0   \n",
      "4225  France   n/a    n/a  01-28-2020        4.0     0.0        0.0   \n",
      "4226  France   n/a    n/a  01-29-2020        5.0     0.0        0.0   \n",
      "4227  France   n/a    n/a  01-30-2020        5.0     0.0        0.0   \n",
      "4228  France   n/a    n/a  01-31-2020        5.0     0.0        0.0   \n",
      "4229  France   n/a    n/a  02-01-2020        6.0     0.0        0.0   \n",
      "4230  France   n/a    n/a  02-02-2020        6.0     0.0        0.0   \n",
      "4231  France   n/a    n/a  02-03-2020        6.0     0.0        0.0   \n",
      "4232  France   n/a    n/a  02-04-2020        6.0     0.0        0.0   \n",
      "4233  France   n/a    n/a  02-05-2020        6.0     0.0        0.0   \n",
      "4234  France   n/a    n/a  02-06-2020        6.0     0.0        0.0   \n",
      "4235  France   n/a    n/a  02-07-2020        6.0     0.0        0.0   \n",
      "4236  France   n/a    n/a  02-08-2020       11.0     0.0        0.0   \n",
      "4237  France   n/a    n/a  02-09-2020       11.0     0.0        0.0   \n",
      "4238  France   n/a    n/a  02-10-2020       11.0     0.0        0.0   \n",
      "4239  France   n/a    n/a  02-11-2020       11.0     0.0        0.0   \n",
      "4240  France   n/a    n/a  02-12-2020       11.0     0.0        2.0   \n",
      "4241  France   n/a    n/a  02-13-2020       11.0     0.0        2.0   \n",
      "4242  France   n/a    n/a  02-14-2020       11.0     0.0        2.0   \n",
      "4243  France   n/a    n/a  02-15-2020       12.0     1.0        4.0   \n",
      "4244  France   n/a    n/a  02-16-2020       12.0     1.0        4.0   \n",
      "4245  France   n/a    n/a  02-17-2020       12.0     1.0        4.0   \n",
      "4246  France   n/a    n/a  02-18-2020       12.0     1.0        4.0   \n",
      "4247  France   n/a    n/a  02-19-2020       12.0     1.0        4.0   \n",
      "4248  France   n/a    n/a  02-20-2020       12.0     1.0        4.0   \n",
      "4249  France   n/a    n/a  02-21-2020       12.0     1.0        4.0   \n",
      "4250  France   n/a    n/a  02-22-2020       12.0     1.0        4.0   \n",
      "4251  France   n/a    n/a  02-23-2020       12.0     1.0        4.0   \n",
      "4252  France   n/a    n/a  02-24-2020       12.0     1.0        4.0   \n",
      "4253  France   n/a    n/a  02-25-2020       14.0     1.0       11.0   \n",
      "4254  France   n/a    n/a  02-26-2020       18.0     2.0       11.0   \n",
      "4255  France   n/a    n/a  02-27-2020       38.0     2.0       11.0   \n",
      "4256  France   n/a    n/a  02-28-2020       57.0     2.0       11.0   \n",
      "4257  France   n/a    n/a  02-29-2020      100.0     2.0       12.0   \n",
      "4258  France   n/a    n/a  03-01-2020      130.0     2.0       12.0   \n",
      "4259  France   n/a    n/a  03-02-2020      191.0     3.0       12.0   \n",
      "4260  France   n/a    n/a  03-03-2020      204.0     4.0       12.0   \n",
      "4261  France   n/a    n/a  03-04-2020      285.0     4.0       12.0   \n",
      "4262  France   n/a    n/a  03-05-2020      377.0     6.0       12.0   \n",
      "4263  France   n/a    n/a  03-06-2020      653.0     9.0       12.0   \n",
      "4264  France   n/a    n/a  03-07-2020      949.0    11.0       12.0   \n",
      "4265  France   n/a    n/a  03-08-2020     1126.0    19.0       12.0   \n",
      "4266  France   n/a    n/a  03-09-2020     1209.0    19.0       12.0   \n",
      "4267  France   n/a    n/a  03-10-2020     1784.0    33.0       12.0   \n",
      "4268  France   n/a    n/a  03-22-2020    16018.0   674.0     2200.0   \n",
      "4269  France   n/a    n/a  03-23-2020    19874.0   860.0     2200.0   \n",
      "4270  France   n/a    n/a  03-24-2020    22304.0  1100.0     3281.0   \n",
      "4271  France   n/a    n/a  03-25-2020    25233.0  1331.0     3900.0   \n",
      "4272  France   n/a    n/a  03-26-2020    29155.0  1696.0     4948.0   \n",
      "4273  France   n/a    n/a  03-27-2020    32964.0  1995.0     5700.0   \n",
      "4274  France   n/a    n/a  03-28-2020    37575.0  2314.0     5700.0   \n",
      "\n",
      "      Confirmed_New  Deaths_New  Recovered_New  \n",
      "4221            NaN         NaN            NaN  \n",
      "4222            1.0         0.0            0.0  \n",
      "4223            0.0         0.0            0.0  \n",
      "4224            0.0         0.0            0.0  \n",
      "4225            1.0         0.0            0.0  \n",
      "4226            1.0         0.0            0.0  \n",
      "4227            0.0         0.0            0.0  \n",
      "4228            0.0         0.0            0.0  \n",
      "4229            1.0         0.0            0.0  \n",
      "4230            0.0         0.0            0.0  \n",
      "4231            0.0         0.0            0.0  \n",
      "4232            0.0         0.0            0.0  \n",
      "4233            0.0         0.0            0.0  \n",
      "4234            0.0         0.0            0.0  \n",
      "4235            0.0         0.0            0.0  \n",
      "4236            5.0         0.0            0.0  \n",
      "4237            0.0         0.0            0.0  \n",
      "4238            0.0         0.0            0.0  \n",
      "4239            0.0         0.0            0.0  \n",
      "4240            0.0         0.0            2.0  \n",
      "4241            0.0         0.0            0.0  \n",
      "4242            0.0         0.0            0.0  \n",
      "4243            1.0         1.0            2.0  \n",
      "4244            0.0         0.0            0.0  \n",
      "4245            0.0         0.0            0.0  \n",
      "4246            0.0         0.0            0.0  \n",
      "4247            0.0         0.0            0.0  \n",
      "4248            0.0         0.0            0.0  \n",
      "4249            0.0         0.0            0.0  \n",
      "4250            0.0         0.0            0.0  \n",
      "4251            0.0         0.0            0.0  \n",
      "4252            0.0         0.0            0.0  \n",
      "4253            2.0         0.0            7.0  \n",
      "4254            4.0         1.0            0.0  \n",
      "4255           20.0         0.0            0.0  \n",
      "4256           19.0         0.0            0.0  \n",
      "4257           43.0         0.0            1.0  \n",
      "4258           30.0         0.0            0.0  \n",
      "4259           61.0         1.0            0.0  \n",
      "4260           13.0         1.0            0.0  \n",
      "4261           81.0         0.0            0.0  \n",
      "4262           92.0         2.0            0.0  \n",
      "4263          276.0         3.0            0.0  \n",
      "4264          296.0         2.0            0.0  \n",
      "4265          177.0         8.0            0.0  \n",
      "4266           83.0         0.0            0.0  \n",
      "4267          575.0        14.0            0.0  \n",
      "4268        14234.0       641.0         2188.0  \n",
      "4269         3856.0       186.0            0.0  \n",
      "4270         2430.0       240.0         1081.0  \n",
      "4271         2929.0       231.0          619.0  \n",
      "4272         3922.0       365.0         1048.0  \n",
      "4273         3809.0       299.0          752.0  \n",
      "4274         4611.0       319.0            0.0  \n"
     ]
    }
   ],
   "source": [
    "print(merged[(merged['Country'] == 'France') & (merged['State'] == 'n/a')])\n",
    "\n",
    "# Run verifications - ignore small deviations\n",
    "df_neg = merged[(merged['County'] != 'Unassigned') & (merged['Confirmed_New'] < -100) | (merged['Deaths_New'] < -50) | (merged['Recovered_New'] < -50)]\n",
    "if df_neg.shape[0] > 0:\n",
    "    print('Some deltas are hugely negative!')\n",
    "    print(df_neg.sort_values('Confirmed_New'))\n",
    "\n",
    "mismatch = merged[(merged['State'] != 'US') & (merged['State'] != 'Recovered') & (merged['County'] != 'Unassigned') & (merged['Confirmed'] - (merged['Deaths'] + merged['Recovered']) < -10)]\n",
    "if mismatch.shape[0] > 0:\n",
    "    print('Confirmed is much smaller than Deaths + Recovered!')\n",
    "    print(mismatch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
